## ğŸ“˜ Tabela wynikÃ³w â€“ interpretacja metryk


| Kolumna             | Znaczenie                                                                              |
| ------------------- | -------------------------------------------------------------------------------------- |
| `Dataset`           | ZbiÃ³r danych, na ktÃ³rym liczono metryki: `train` (treningowy), `test`                  |
| `Accuracy`          | Procent wszystkich prÃ³bek, ktÃ³re zostaÅ‚y poprawnie sklasyfikowane                      |
| `Precision (macro)` | Åšrednia precyzja dla kaÅ¼dej klasy â€“ ile z przewidzianych â€takâ€ to byÅ‚o prawdziwe â€takâ€ |
| `Recall (macro)`    | Åšrednia czuÅ‚oÅ›Ä‡ â€“ ile prawdziwych â€takâ€ zostaÅ‚o poprawnie wykrytych                    |
| `F1-score (macro)`  | Åšrednia harmoniczna precyzji i czuÅ‚oÅ›ci â€“ rÃ³wnowaÅ¼y oba wskaÅºniki                      |
| `Model`             | Nazwa modelu â€“ tutaj: `Logistic Regression` (sklearn vs wÅ‚asna wersja)                 |


## Tabela wynikÃ³w dla wÅ‚asnej implementacji sklearn ( zadanie 3.0 )
![alt text](image-1.png)

## Tabela wynikÃ³w dla wÅ‚asnej implementacji regresji logistycznej ( zadanie 4.0 )
![alt text](image.png)

## ğŸ“Š PorÃ³wnanie wynikÃ³w regresji logistycznych


| Dataset   | Metryka           | Sklearn (`zadanie 3.0`) | WÅ‚asna (`zadanie 4.0`) |
| --------- | ----------------- | ----------------------- | ---------------------- |
| **train** | Accuracy          | 0.92                    | 0.92                   |
|           | Precision (macro) | 0.93                    | 0.92                   |
|           | Recall (macro)    | 0.91                    | 0.90                   |
|           | F1-score (macro)  | 0.92                    | 0.91                   |
| **test**  | Accuracy          | 0.91                    | 0.91                   |
|           | Precision (macro) | 0.92                    | 0.91                   |
|           | Recall (macro)    | 0.90                    | 0.90                   |
|           | F1-score (macro)  | 0.91                    | 0.90                   |


## Wnioski 

Obie wersje modelu dajÄ… prawie identyczne wyniki, co oznacza, Å¼e  wÅ‚asna implementacja dziaÅ‚a bardzo dobrze.

Sklearn jest minimalnie lepszy, co prawdopodobnie wynika z zastosowania:

lepszego optymalizatora 

wbudowanej regularyzacji L2

precyzyjnych tolerancji numerycznych

RÃ³Å¼nice â‰¤ 0.01

## 4.0 1b Przeanalizuj ograniczenia zastosowania zamkniÄ™tej formuÅ‚y. Dlaczego nie jest w praktyce wykorzysytwana?

- Koszt obliczeniowy i pamiÄ™ciowy
Aby obliczyÄ‡,MnoÅ¼enie macierzy, operacji, a odwrÃ³cenie tej macierzy to 
Gdy masz np. 10 000 cech, odwracanie macierzy wymaga setek miliardÃ³w operacji i ogromnej iloÅ›ci pamiÄ™ci RAM.

- Brak skalowalnoÅ›ci do ogromnych danych
Dla zbiorÃ³w o milionach prÃ³bek lub dziesiÄ…tkach tysiÄ™cy cech pojÄ™cie â€wszystko w pamiÄ™ciâ€ siÄ™ rozpada.

- Prawdziwe aplikacje uczÄ… modele na strumieniach danych lub w miniâ€batchach, co zamkniÄ™ta formuÅ‚a uniemoÅ¼liwia.

-  Tylko regresja liniowa
ZamkniÄ™ta formuÅ‚a zadziaÅ‚a jedynie dla regresji z MSE (bÅ‚Ä™dem kwadratowym) i modelu liniowego.

- Nie zastosujesz jej do:
- regresji logistycznej (crossâ€entropy)
- sieci neuronowych
- innych funkcji kosztu, ktÃ³re nie dajÄ… siÄ™ sprowadziÄ‡ do odwrÃ³cenia jednej macierzy.
