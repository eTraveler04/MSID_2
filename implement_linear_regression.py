#!/usr/bin/env python3
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def closed_form_regression(X, y):
    """
    Oblicza wagi w regresji liniowej metodÄ… closed-form:
        w = (X^T X)^{-1} X^T y
    X powinno zawieraÄ‡ juÅ¼ kolumnÄ™ bias (jedynki).
    """
    XtX     = X.T @ X
    XtX_inv = np.linalg.inv(XtX)
    Xty     = X.T @ y
    return XtX_inv @ Xty

def main():
    results_dir = "reg_results"
    os.makedirs(results_dir, exist_ok=True)

    # 1. Wczytanie danych (wszystkie kolumny numeryczne)
    df = pd.read_csv("data/formatted_dataset.csv")

    counts = df["Target"].value_counts().sort_index()  # liczba prÃ³bek w kaÅ¼dej klasie
    props  = df["Target"].value_counts(normalize=True).sort_index() * 100  # procentowo

    print("RozkÅ‚ad klas w Target (liczba prÃ³bek):")
    print(counts)
    print("\nRozkÅ‚ad klas w Target (procentowo):")
    print(props.round(2).astype(str) + " %")

    # 2. Przygotowanie X i y â€” tutaj y = "Age at enrollment"
    target = "Age at enrollment"
    y      = df[target].to_numpy()
    X      = df.drop(columns=[target]).to_numpy()

    # 3. PodziaÅ‚ na trening/test (80/20)
    n_samples       = X.shape[0]
    split           = int(0.8 * n_samples)
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    # 4. Standaryzacja cech (na podstawie X_train)
    mean = X_train.mean(axis=0)
    std  = X_train.std(axis=0)
    std[std == 0] = 1
    X_train = (X_train - mean) / std
    X_test  = (X_test  - mean) / std

    # 5. Dodanie kolumny bias (jedynki)
    X_train_bias = np.hstack([np.ones((X_train.shape[0],1)), X_train])
    X_test_bias  = np.hstack([np.ones((X_test.shape[0],1)),  X_test])

    # 6. Obliczenie wag (closed-form)
    w = closed_form_regression(X_train_bias, y_train)

    # 7. Predykcja
    y_pred = X_test_bias @ w

    # 8a. Mean Squared Error
    mse = np.mean((y_pred - y_test)**2)
    print(f"MSE (closed-form, standaryzowane) na kolumnie {target}: {mse:.4f}")

    # 8b. Dodatkowe metryki dla regresji
    mae  = np.mean(np.abs(y_pred - y_test))          # Mean Absolute Error
    rmse = np.sqrt(mse)                              # Root Mean Squared Error
    ss_res = np.sum((y_test - y_pred)**2)            # suma kwadratÃ³w reszt
    ss_tot = np.sum((y_test - np.mean(y_test))**2)   # caÅ‚kowita suma wariancji
    r2   = 1 - ss_res/ss_tot                         # wspÃ³Å‚czynnik determinacji

    print(f"MAE : {mae:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"R^2 : {r2:.4f}")


    # 9. Zapis wynikÃ³w do CSV
    preds_path   = os.path.join(results_dir, "predictions_closed_form.csv")
    weights_path = os.path.join(results_dir, "weights_closed_form.csv")

    pd.DataFrame({
        "y_true": y_test,
        "y_pred": y_pred
    }).to_csv(preds_path, index=False)

    pd.Series(w, name="weight").to_csv(weights_path, index=False)

    print("ðŸ”– Zapisano pliki:")
    print(f" - {preds_path}")
    print(f" - {weights_path}")

    # ----------------------------
    # 10. Generowanie wykresÃ³w
    # ----------------------------
    # Obliczenie residuÃ³w
    residuals = y_test - y_pred

    # 10.1 Scatter: rzeczywiste vs predykowane
    plt.figure()
    plt.scatter(y_test, y_pred, alpha=0.6)
    # linia y=x dla odniesienia
    mn, mx = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())
    plt.plot([mn, mx], [mn, mx], 'r--')
    plt.xlabel("Rzeczywiste y")
    plt.ylabel("Predykowane y")
    plt.title("Scatter: Rzeczywiste vs Predykowane")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(results_dir, "true_vs_pred.png"))
    plt.close()

    # 10.2 Histogram residuÃ³w
    plt.figure()
    plt.hist(residuals, bins=30, edgecolor='black')
    plt.xlabel("Residua (y_true - y_pred)")
    plt.ylabel("Liczba prÃ³bek")
    plt.title("Histogram residuÃ³w")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(results_dir, "residuals_hist.png"))
    plt.close()

    # 10.3 Residua vs wartoÅ›ci predykowane
    plt.figure()
    plt.scatter(y_pred, residuals, alpha=0.6)
    plt.axhline(0, color='r', linestyle='--')
    plt.xlabel("Predykowane y")
    plt.ylabel("Residua")
    plt.title("Residua vs Predykowane y")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(results_dir, "residuals_vs_pred.png"))
    plt.close()

    print("ðŸ“Š Wykresy zapisane w:", results_dir)

if __name__ == "__main__":
    main()


# #!/usr/bin/env python3
# import os
# import numpy as np
# import pandas as pd
# import matplotlib.pyplot as plt

# def closed_form_regression(X, y):
#     """
#     Oblicza wagi w regresji liniowej metodÄ… closed-form:
#         w = (X^T X)^{-1} X^T y
#     X powinno zawieraÄ‡ juÅ¼ kolumnÄ™ bias (jedynki).
#     """
#     XtX     = X.T @ X
#     XtX_inv = np.linalg.inv(XtX)
#     Xty     = X.T @ y
#     return XtX_inv @ Xty

# def main():
#     results_dir = "reg_results"
#     os.makedirs(results_dir, exist_ok=True)

#     # 1. Wczytanie danych (wszystkie kolumny numeryczne)
#     df = pd.read_csv("data/formatted_dataset.csv")

#     counts = df["Target"].value_counts().sort_index()
#     props  = df["Target"].value_counts(normalize=True).sort_index() * 100

#     print("RozkÅ‚ad klas w Target (liczba prÃ³bek):")
#     print(counts)
#     print("\nRozkÅ‚ad klas w Target (procentowo):")
#     print(props.round(2).astype(str) + " %")

#     # ðŸ” 1b. Usuwanie silnie skorelowanych kolumn
#     correlation_matrix = df.corr(numeric_only=True).abs()
#     upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))
#     to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]

#     if to_drop:
#         print("Usuwam kolumny z silnÄ… korelacjÄ…:", to_drop)
#         df.drop(columns=to_drop, inplace=True)
#         with open(os.path.join(results_dir, "dropped_columns.txt"), "w") as f:
#             f.write("\n".join(to_drop))
#     else:
#         print("Brak kolumn o korelacji > 0.95 â€“ nic nie usuniÄ™to.")

#     # 2. Przygotowanie X i y â€” tutaj y = "Age at enrollment"
#     target = "Age at enrollment"
#     y      = df[target].to_numpy()
#     X      = df.drop(columns=[target]).to_numpy()

#     # 3. PodziaÅ‚ na trening/test (80/20)
#     n_samples       = X.shape[0]
#     split           = int(0.8 * n_samples)
#     X_train, X_test = X[:split], X[split:]
#     y_train, y_test = y[:split], y[split:]

#     # 4. Standaryzacja cech (na podstawie X_train)
#     mean = X_train.mean(axis=0)
#     std  = X_train.std(axis=0)
#     std[std == 0] = 1
#     X_train = (X_train - mean) / std
#     X_test  = (X_test  - mean) / std

#     # 5. Dodanie kolumny bias (jedynki)
#     X_train_bias = np.hstack([np.ones((X_train.shape[0],1)), X_train])
#     X_test_bias  = np.hstack([np.ones((X_test.shape[0],1)),  X_test])

#     # 6. Obliczenie wag (closed-form)
#     w = closed_form_regression(X_train_bias, y_train)

#     # 7. Predykcja
#     y_pred = X_test_bias @ w

#     # 8a. Mean Squared Error
#     mse = np.mean((y_pred - y_test)**2)
#     print(f"MSE (closed-form, standaryzowane) na kolumnie {target}: {mse:.4f}")

#     # 8b. Dodatkowe metryki dla regresji
#     mae  = np.mean(np.abs(y_pred - y_test))
#     rmse = np.sqrt(mse)
#     ss_res = np.sum((y_test - y_pred)**2)
#     ss_tot = np.sum((y_test - np.mean(y_test))**2)
#     r2   = 1 - ss_res / ss_tot

#     print(f"MAE : {mae:.4f}")
#     print(f"RMSE: {rmse:.4f}")
#     print(f"R^2 : {r2:.4f}")

#     # 9. Zapis wynikÃ³w do CSV
#     preds_path   = os.path.join(results_dir, "predictions_closed_form.csv")
#     weights_path = os.path.join(results_dir, "weights_closed_form.csv")

#     pd.DataFrame({
#         "y_true": y_test,
#         "y_pred": y_pred
#     }).to_csv(preds_path, index=False)

#     pd.Series(w, name="weight").to_csv(weights_path, index=False)

#     print("ðŸ”– Zapisano pliki:")
#     print(f" - {preds_path}")
#     print(f" - {weights_path}")

#     # 10. Generowanie wykresÃ³w
#     residuals = y_test - y_pred

#     plt.figure()
#     plt.scatter(y_test, y_pred, alpha=0.6)
#     mn, mx = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())
#     plt.plot([mn, mx], [mn, mx], 'r--')
#     plt.xlabel("Rzeczywiste y")
#     plt.ylabel("Predykowane y")
#     plt.title("Scatter: Rzeczywiste vs Predykowane")
#     plt.grid(True)
#     plt.tight_layout()
#     plt.savefig(os.path.join(results_dir, "true_vs_pred.png"))
#     plt.close()

#     plt.figure()
#     plt.hist(residuals, bins=30, edgecolor='black')
#     plt.xlabel("Residua (y_true - y_pred)")
#     plt.ylabel("Liczba prÃ³bek")
#     plt.title("Histogram residuÃ³w")
#     plt.grid(True)
#     plt.tight_layout()
#     plt.savefig(os.path.join(results_dir, "residuals_hist.png"))
#     plt.close()

#     plt.figure()
#     plt.scatter(y_pred, residuals, alpha=0.6)
#     plt.axhline(0, color='r', linestyle='--')
#     plt.xlabel("Predykowane y")
#     plt.ylabel("Residua")
#     plt.title("Residua vs Predykowane y")
#     plt.grid(True)
#     plt.tight_layout()
#     plt.savefig(os.path.join(results_dir, "residuals_vs_pred.png"))
#     plt.close()

#     print("ðŸ“Š Wykresy zapisane w:", results_dir)

# if __name__ == "__main__":
#     main()
